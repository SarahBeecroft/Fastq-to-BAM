#!/bin/bash

#########################################################
# 
# Platform: NCI Gadi HPC
# Description: run GATK Base Recalibrator over parallel tasks
# Usage: first, run 'bash bqsr_recal_make_input.sh <cohort_name>', 
# then execute this script with 'qsub bqsr_recal_run_parallel.pbs'
# Details:
# 	Run GATK BaseRecalibrator in 32 parallel chunks per sample
# 	For tumour/normal, run time is ~ half for normal so best to split
# 	into 2 jobs. GATK4 does not multithread, but this each tasks needs 
# 	2 CPU worth of RAM. Average recal time for one tumour split interval 
#	(60X) is ~20 mins, and ~ 10 mins for blood (30X). Use this to work 
#	out the expected walltime based on the number of tasks reported by 
#	the 'make_input'script, eg for 6 normal samples
# 	that is 6 X 32 = 192 tasks total, at 2 CPU per task = 384 cores which is 
# 	8 nodes. Given this is a small dataset, I would request 8 nodes for 20
# 	minutes (double the expected walltime as a buffer). For larger datasets, 
# 	I reduce the ratio of nodes per sample, eg for 80 blood samples, 30 nodes 
# 	yields ~ 32 mins time, and for 80 tumour samples, 30 nodes yields 65 mins 
#	walltime. For 16 cancer samples, 16 x 32 = 512 tasks, x 2 CPU = 1024 CPU 
#	or 21.3 nodes. Requesting 22 nodes at 40 mins walltime would be fine for 
#	this example dataset size. Efficiency will be slightly lower but given 
#	the time per interval is fairly constant and can't be ordered in a specific 
#	way based on exected walltime (I have tested this), reducing the nodes 
#	won't help much (a little, as the idle cores at eg 22 nodes for this dataset
#	will be 32 and at 11 nodes will be 16 idle cores. It should only run for 20 
#	mins so the SU cost of the 32 idle cores won't add too much cost to the job.
#
# Author: Cali Willet
# cali.willet@sydney.edu.au
# Date last modified: 24/07/2020
#
# If you use this script towards a publication, please acknowledge the
# Sydney Informatics Hub (or co-authorship, where appropriate).
#
# Suggested acknowledgement:
# The authors acknowledge the scientific and technical assistance 
# <or e.g. bioinformatics assistance of <PERSON>> of Sydney Informatics
# Hub and resources and services from the National Computational 
# Infrastructure (NCI), which is supported by the Australian Government
# with access facilitated by the University of Sydney.
# 
#########################################################     
 

#PBS -P <project>
#PBS -N bqsr-tumour
#PBS -l walltime=00:40:00
#PBS -l ncpus=1056
#PBS -l mem=4180GB
#PBS -q normal
#PBS -W umask=022 
#PBS -l wd 
#PBS -o ./Logs/bqsr_recal-tumour.o 
#PBS -e ./Logs/bqsr_recal-tumour.e 
#PBS -lstorage=scratch/<project>
 
module load openmpi/4.0.2
module load nci-parallel/1.0.0

set -e

SCRIPT=./bqsr_recal.sh  
INPUTS=./Inputs/bqsr_recal.inputs-tumour

mkdir -p ./BQSR_tables ./Logs/BQSR_recal ./Error_capture/BQSR_recal

NCPUS=2


#########################################################
# Do not edit below this line (unless running on a node that 
# does not have 48 CPU, in which case edit the value of 'CPN'
#########################################################

CPN=48 #CPUs per node 
M=$(( CPN / NCPUS )) #tasks per node

sed "s|^|${SCRIPT} |" ${INPUTS} > ${PBS_JOBFS}/input-file

mpirun --np $((M * PBS_NCPUS / CPN)) \
        --map-by node:PE=${NCPUS} \
        nci-parallel \
        --verbose \
        --input-file ${PBS_JOBFS}/input-file
